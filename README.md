# PySpark Introduction

## General Information
This repository contains notebooks based on the CodeCademy course **"Introduction to Big Data with PySpark"**.  
The course provides a practical introduction to distributed data processing using Apache Spark and PySpark.

Covered topics:
- Introduction to Big Data concepts
- Working with Spark RDDs using PySpark
- Working with Spark DataFrames and SQL

## Project Structure
This project includes Jupyter Notebooks with hands-on examples of data processing and analysis using PySpark.

### Notebooks with general PySpark functions and examples of analyses
| Notebook | Description |
|----------|-------------|
| `PySpark Fundamentals.ipynb` | How to create a Spark session and work with RDDs |
| `Spark SQL - Introduction.ipynb` | Basics of Spark SQL and working with DataFrames |
| `Analysis in PySpark.ipynb` | Examples of PySpark methods for data analysis |
| `Analysis in Spark SQL.ipynb` | Examples of Spark SQL queries for data analysis |

### Notebooks presenting data analysis of real datasets
| Notebook | Description |
|----------|-------------|
| `Analyzing Common Crawl Data with PySpark.ipynb` | Real-world example: analyzing Common Crawl web data |
| `Analyzing Wikipedia Clickstreams with PySpark.ipynb` | Analyzing Wikipedia clickstream data using PySpark |

## Installation & Usage
To run the notebooks locally, make sure you have:
- Python 3.8+
- PySpark
- Jupyter Notebook or JupyterLab

You can install required packages with:

```bash
pip install pyspark notebook
